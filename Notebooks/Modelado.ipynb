{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Individual 1 (MLOPs): Sistema de Recomendación de Películas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Importamos las librerías necesarias'''\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Importamos el dataset'''\n",
    "\n",
    "movies_df = pd.read_csv('C:/Users/Luis/Documents/Universidad-Trabajo/SoyHenry/LABS/Proyecto_1/Datasets/Movies_limpio.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Antes de realizar el modelado, haremos algunos cambios en el conjunto de datos para reducir la cantidad de datos\n",
    "    y poder correr los diferentes algoritmos. Esto no se realizó antes para que el dataset pueda funcionar en las\n",
    "    diferentes funciones de la api'''\n",
    "\n",
    "'''Eliminamos las películas que no hayan sido lanzadas, es decir, que su status sea diferente a released'''\n",
    "\n",
    "movies_df = movies_df[movies_df['status'] == 'Released']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Del EDA observamos que hay outliers en la columna runtime. En este caso dejaremos los valores que sean mayores\n",
    "    a 0 minutos y menores a 500 minutos, considerando que en promedio una película dura entre 60 a 180 minutos'''\n",
    "\n",
    "movies_df = movies_df[(movies_df['runtime'] > 0) & (movies_df['runtime'] <= 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Del EDA también observamos que no es hasta el año 1920 que se comienzan a producir mayor cantidad de películas.\n",
    "    Por esto se dejarán solo las películas que se hayan estrenado a partir de 1920.'''\n",
    "\n",
    "movies_df = movies_df[movies_df['release_year'] >= 1920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Considerando que las películas más votadas por los fans son las más populares, pudiendo observarse una correlación\n",
    "    entre las variables en el heatmap y pairplot realizado en el EDA, se eliminarán los registros que tengan menos de 150\n",
    "    en la columna vote_count.'''\n",
    "\n",
    "movies_df = movies_df[movies_df['vote_count'] >= 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Como se hará un procesamiento de lenguaje natural, se utilizará un parámetro en el modelo llamado stopwords\n",
    "    que depende del idioma, se trabajará con inglés por ser el lenguaje mayoritario. Por esto, se eliminan aquellas\n",
    "    películas cuyo lenguaje original no sea inglés'''\n",
    "\n",
    "movies_df = movies_df[movies_df['original_language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'id', 'original_language', 'overview', 'popularity',\n",
       "       'production_companies', 'release_date', 'revenue', 'runtime', 'status',\n",
       "       'title', 'vote_average', 'vote_count', 'cast', 'name_collection',\n",
       "       'directors', 'release_year', 'return', 'title_list', 'union'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Reseteamos los índices y borramos las columna que son innecesarias para el modelo'''\n",
    "\n",
    "movies_df = movies_df.reset_index()\n",
    "movies_df.drop(columns = ['index', 'budget', 'genres', 'original_language', 'overview', 'popularity', 'production_companies', 'release_date', 'revenue', 'runtime', 'status', 'vote_average', 'vote_count', 'cast', 'name_collection', 'directors', 'release_year', 'return', 'title_list'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilizaremos a librería nltk, especificamente el módulo de stemming para realizar la derivación\n",
    "    de la columna unión'''\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "''' Creamos una función que realizará la derivación a toda la columna'''\n",
    "\n",
    "def stemming(column):\n",
    "    union_list = []\n",
    "    for l in column:\n",
    "        union_list.append(stemmer.stem(l))\n",
    "    \n",
    "    return ' '.join(union_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Normalizamos la columna union, para reducir la cantidad de palabras y quedarnos con las más importantes'''\n",
    "\n",
    "movies_df['union'] = movies_df['union'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",str(x))) # reemplazamos los caracteres que no sean letras por espacios\n",
    "movies_df['union'] = movies_df['union'].apply(lambda x: x.lower()) # Llevamos todo a minúsculas\n",
    "movies_df['union'] = movies_df['union'].apply(lambda x: nltk.word_tokenize(x)) # Tokenizamos\n",
    "\n",
    "''' Aplicamos la función stemming'''\n",
    "\n",
    "movies_df['union'] = movies_df['union'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creamos un nuevo archivo csv a partir del movies_df. Este archivo será el usado en la función de recomendación\n",
    "    de la API.'''\n",
    "\n",
    "movies_df.to_csv('C:/Users/Luis/Documents/Universidad-Trabajo/SoyHenry/LABS/Proyecto_1/Datasets/Movies_modelo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Vectorizamos la columna union y se remueven las stopwords'''\n",
    "\n",
    "cv = TfidfVectorizer(max_features = 2000, stop_words = 'english')\n",
    "\n",
    "vector = cv.fit_transform(movies_df['union']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luis\\Documents\\Universidad-Trabajo\\SoyHenry\\LABS\\Proyecto_1\\env_PI_1\\Lib\\site-packages\\sklearn\\utils\\extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "''' Se utiliza el módulo cosine_similarity de sklearn, para establecer las distancias entre los diferentes\n",
    "    valores del vector creado, es decir, entre los valores de la columna union'''\n",
    "\n",
    "similarity = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
